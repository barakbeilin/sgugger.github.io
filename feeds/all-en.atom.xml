<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Another data science student's blog</title><link href="/" rel="alternate"></link><link href="/feeds/all-en.atom.xml" rel="self"></link><id>/</id><updated>2018-03-20T16:15:00-04:00</updated><entry><title>How Do You Find A Good Learning Rate</title><link href="/how-do-you-find-a-good-learning-rate.html" rel="alternate"></link><published>2018-03-20T16:15:00-04:00</published><updated>2018-03-20T16:15:00-04:00</updated><author><name>Sylvain Gugger</name></author><id>tag:None,2018-03-20:/how-do-you-find-a-good-learning-rate.html</id><summary type="html">&lt;p class="first last"&gt;This is the main hyper-parameter to set when we train a neural net, but how do you determine the best value? Here's a technique to quickly decide on one.&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="the-theory"&gt;
&lt;h2&gt;The theory&lt;/h2&gt;
&lt;p&gt;How do you decide on a learning rate? If it's too slow, your neural net is going to take forever to learn (try to use &lt;span class="math"&gt;\(10^{-5}\)&lt;/span&gt; instead of &lt;span class="math"&gt;\(10^{-2}\)&lt;/span&gt; in
&lt;a class="reference external" href="/a-neural-net-in-pytorch.html"&gt;the previous article&lt;/a&gt; for instance). But if it's too high, each step you take will go over the minimum and you'll never get to an acceptable loss.
Worse, a high learning rate could lead you to an increasing loss until it reaches nan.&lt;/p&gt;
&lt;p&gt;Why is that? If your gradients are really high, then a high learning rate is going to take you to a spot that's so far away from the minimum you will probably be worse than before
in terms of loss. Even on something as simple as a parabola, see how a high learning rate quickly gets you further and further away from the minima.&lt;/p&gt;
&lt;img alt="" class="align-center" src="../images/art2_explode.png" style="width: 500px;" /&gt;
&lt;p&gt;So we have to pick exactly the right value, not too high and not too low. For a long time, it's been a game of try and see, but in &lt;a class="reference external" href="https://arxiv.org/abs/1506.01186"&gt;this article&lt;/a&gt; another approach is presented. Over an epoch begin your SGD with a very low learning rate (like &lt;span class="math"&gt;\(10^{-8}\)&lt;/span&gt;) but change it
(by multiplying it by a certain factor for instance)
at each mini-batch until it reaches a very high value (like 1 or 10). Record the loss each time at each iteration and once you're finished, plot those losses against the learning
rate. You'll find something like this:&lt;/p&gt;
&lt;img alt="Plot of the loss against the learning rate" class="align-center" src="../images/art2_courbe_lr.png" /&gt;
&lt;p&gt;The loss decreases at the beginning, then it stops and it goes back increasing, usually extremely quickly. That's because with very low learning rates, we get better and better,
especially since we increase them. Then comes a point where we reach a value that's too high and the phenomenon shown before happens. Looking at this graph, what is the best
learning rate to choose? Not the one corresponding to the minimum.&lt;/p&gt;
&lt;p&gt;Why? Well the learning rate that corresponds to the minimum value is already a bit too high, since we are at the edge between improving and getting all over the place.
We want to go one order of magnitude before, a value that's still aggressive (so that we train quickly) but still on the safe side from an explosion. In the example described by
the picture above, for instance, we don't want to pick &lt;span class="math"&gt;\(10^{-1}\)&lt;/span&gt; but rather &lt;span class="math"&gt;\(10^{-2}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This method can be applied on top of every variant of SGD, and any kind of network. We just have to go through one epoch (usually less) and record the values of our loss
to get the data for our plot.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="in-practice"&gt;
&lt;h2&gt;In practice&lt;/h2&gt;
&lt;p&gt;How do we code this? Well it's pretty simple when we use the fastai library. As detailed in the &lt;a class="reference external" href="http://course.fast.ai/lessons/lesson1.html"&gt;first lesson&lt;/a&gt;, if we have built a learner object for our model, we just have
to type&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;learner&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lr_find&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;learner&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sched&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;and we'll get a picture very similar as then one above. Let's do it ourselves though, to be sure we have understood everything there is behind the scenes. It's going to be pretty
easy since we just have to adapt the training loop seen in &lt;a class="reference external" href="/a-neural-net-in-pytorch.html"&gt;that article&lt;/a&gt; there is just a few tweaks.&lt;/p&gt;
&lt;p&gt;The first one is that we won't really plot the loss of each mini-batch, but some smoother version of it. If we tried to plot the raw loss, we would end up with a graph like
this one:&lt;/p&gt;
&lt;img alt="Plot of the loss against the learning rate" class="align-center" src="../images/art2_loss_vs_lr.png" /&gt;
&lt;p&gt;Even if we can see a global trend (and that's because I truncated the part where it goes up to infinity on the right), it's not as clear as the previous graph. To smooth those
losses we will take their exponentially weighed averages. It sounds far more complicated that it is and if you're familiar with the momentum variant of SGD it's exactly
the same. At each step where we get a loss, we define this average loss by&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{avg loss} = \beta * \hbox{old avg loss} + (1-\beta) * \hbox{loss}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; is a parameter we get to pick between 0 and 1. This way the average losses will reduce the noise and give us a smoother graph where we'll definitely be able to
see the trend. This also also explains why we are &lt;em&gt;too late&lt;/em&gt; when we reach the minimum in our first curve: this averaged loss will stay low when our losses start to explode, and
it'll take a bit of time before it starts to really increase.&lt;/p&gt;
&lt;p&gt;If you don't see the exponentially weighed behind this average, it's because it's hidden in our recursive formula. If our losses are &lt;span class="math"&gt;\(l_{0},\dots,l_{n}\)&lt;/span&gt; then the
exponentially weighed loss at a given index &lt;span class="math"&gt;\(i\)&lt;/span&gt; is&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{avg loss}_{i} = (1-\beta) \beta^{i} l_{0} + (1-\beta) \beta^{i-1} l_{1} + \cdots + (1-\beta) \beta l_{i-1} + (1-\beta) l_{i}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;so the weights are all powers of &lt;span class="math"&gt;\(\beta\)&lt;/span&gt;. If remember the formula giving the sum of a geometric sequence, the sum of our weights is&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
(1-\beta) \beta^{i} + (1-\beta) \beta^{i-1} + \cdots + (1-\beta) \beta + (1-\beta) = (1-\beta) * \frac{1-\beta^{i+1}}{1-\beta} = 1-\beta^{i+1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;so to really be an average, we have to divide our average loss by this factor. In the end, the loss we will plot is&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{smoothed loss}_{i} = \frac{\hbox{avg loss}_{i}}{1-\beta^{i+1}}.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;This doesn't really change a thing when &lt;span class="math"&gt;\(i\)&lt;/span&gt; is big, because &lt;span class="math"&gt;\(\beta^{i+1}\)&lt;/span&gt; will be very close to 0. But for the first values of &lt;span class="math"&gt;\(i\)&lt;/span&gt;, it insures we get better
results.&lt;/p&gt;
&lt;p&gt;The next thing we will change in our training loop is that we probably won't need to do one whole epoch: if the loss is starting to explode, we probably don't want to continue.
The criteria that's implemented in the fastai library and that seems to work pretty well is:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{current smoothed loss} &amp;gt; 4 \times \hbox{minimum smoothed loss}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Lastly, we need just a tiny bit of math to figure out by how much to multiply our learning rate at each step. If we begin with a learning rate of &lt;span class="math"&gt;\(\hbox{lr}_{0}\)&lt;/span&gt; and
multiply it at each step by &lt;span class="math"&gt;\(q\)&lt;/span&gt; then at the &lt;span class="math"&gt;\(i\)&lt;/span&gt;-th step, our learning rate will be&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{lr}_{i} = \hbox{lr}_{0} \times q^{i}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Now, we want to figure out &lt;span class="math"&gt;\(q\)&lt;/span&gt; knowing &lt;span class="math"&gt;\(\hbox{lr}_{0}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\hbox{lr}_{N-1}\)&lt;/span&gt; (the final value after &lt;span class="math"&gt;\(N\)&lt;/span&gt; steps) so we isolate it:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{lr}_{N-1} = \hbox{lr}_{0} \times q^{N-1} \quad \Longleftrightarrow \quad q^{N-1} = \frac{\hbox{lr}_{N-1}}{\hbox{lr}_{0}} \quad \Longleftrightarrow \quad q = \left ( \frac{\hbox{lr}_{N-1}}{\hbox{lr}_{0}}  \right )^{\frac{1}{N-1}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;With all of this, we're ready to alter our previous training loop. This all supposes that you've got a neural net defined (in the variable called net), a data loader called
trn_loader, an optimizer and a loss function (called criterion).&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;find_lr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_value&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;final_value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;10.&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.98&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trn_loader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;mult&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;final_value&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;init_value&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;lr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;init_value&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param_groups&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'lr'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;
    &lt;span class="n"&gt;avg_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
    &lt;span class="n"&gt;best_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
    &lt;span class="n"&gt;batch_num&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;losses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;log_lrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;trn_loader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;batch_num&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="c1"&gt;#As before, get the loss for this mini-batch of inputs/outputs&lt;/span&gt;
        &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
        &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zero_grad&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;criterion&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;#Compute the smoothed loss&lt;/span&gt;
        &lt;span class="n"&gt;avg_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;avg_loss&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;smoothed_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;avg_loss&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;beta&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;batch_num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;#Stop if the loss is exploding&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;batch_num&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;smoothed_loss&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;best_loss&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;log_lrs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;losses&lt;/span&gt;
        &lt;span class="c1"&gt;#Record the best loss&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;smoothed_loss&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;best_loss&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;batch_num&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;best_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;smoothed_loss&lt;/span&gt;
        &lt;span class="c1"&gt;#Store the values&lt;/span&gt;
        &lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;smoothed_loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;log_lrs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log10&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="c1"&gt;#Do the SGD step&lt;/span&gt;
        &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="c1"&gt;#Update the lr for the next step&lt;/span&gt;
        &lt;span class="n"&gt;lr&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;mult&lt;/span&gt;
        &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;param_groups&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;'lr'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;lr&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;log_lrs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;losses&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Note that the learning rate is found into the dictionary stored in optimizer.param_groups. If we go back to our notebook with the MNIST data set, we can then define our
neural net, an optimizer and the loss function.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SimpleNeuralNet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SGD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;criterion&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nll_loss&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;And after this we can call this function to find our learning rate and plot the results.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;find_lr&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The skip of the first 10 values and the last 5 is another thing that the fastai library does by default, to remove the initial and final high losses and focus on the interesting
parts of the graph. I added all of this at the end of the previous notebook, and you can find it &lt;a class="reference external" href="https://github.com/sgugger/Deep-Learning/blob/master/Learning%20rate%20finder.ipynb"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This code modifies the neural net and its optimizer, so we have to be careful to reinitialize those after doing this, to the best value we can. An amelioration to the code
would be to save it then reload the initial state when we're done (which is what the fastai library does).&lt;/p&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="SGD"></category><category term="Learning rate"></category></entry><entry><title>A Neural Net In Pytorch</title><link href="/a-neural-net-in-pytorch.html" rel="alternate"></link><published>2018-03-16T10:13:00-04:00</published><updated>2018-03-16T10:13:00-04:00</updated><author><name>Sylvain Gugger</name></author><id>tag:None,2018-03-16:/a-neural-net-in-pytorch.html</id><summary type="html">&lt;p class="first last"&gt;The theory is all really nice, but let's actually build a neural net and train it! We'll see how a simple neural net with one hidden layer can learn to recognize digits very efficiently.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;This article goes with &lt;a class="reference external" href="https://github.com/sgugger/Deep-Learning/blob/master/First%20neural%20net%20in%20pytorch.ipynb"&gt;this notebook&lt;/a&gt; if you want to really do the experiment.
In particular, I won't explain the specifics of getting the data and preprocessing it here.&lt;/p&gt;
&lt;div class="section" id="pytorch"&gt;
&lt;h2&gt;Pytorch&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="http://pytorch.org/"&gt;Pytorch&lt;/a&gt; is a Python library that provides all what is needed to implement Deep Learning easily. In particular, it enables GPU-accelerated computations and provides
automatic differentiation. We have seen why the latter is useful in the &lt;a class="reference external" href="/what-is-deep-learning.html"&gt;previous article&lt;/a&gt;, and this the reason why we will never have to worry
about calculating gradients (unless we really want to dig into that).&lt;/p&gt;
&lt;p&gt;But why GPUs? As we have seen, Deep Learning is just a succession of linear operations with a few functions applied element-wise in between, and it happens that GPUs are really
good (and fast!) at those, because that's what is basically needed to decide which color should each pixel of the screen have when playing a game. Thanks to the gaming industry,
research on GPUs has made them extremely efficient, which is also why Deep Learning has become better in a lot of different areas. We can consider deeper network and train
them on much more data nowadays.&lt;/p&gt;
&lt;p&gt;To use the full potential of this library, we're going to need one, preferably several, efficient GPU. A gaming computer can have one, but the best way is to rent some. Services
to rent GPUs by the hour have flourished and you can easily find some powerful virtual machines with efficient GPUs for less than fifty cents an hour. I'm personally using
Paperspace at the moment.&lt;/p&gt;
&lt;p&gt;I'm mostly using pytorch because the library of fast.ai is built on top of it, but I really like the way it uses Python functionalities (as we'll see, it makes good use of
Object Oriented Programming in Python) and the fact the gradients are dynamically computed. It's making the implementation of Recurrent Neural Networks a lot easier in my
opinion, but we'll see more of that later.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mnist-dataset"&gt;
&lt;h2&gt;MNIST Dataset&lt;/h2&gt;
&lt;p&gt;To have some data on which try our neural net, we will use the MNIST Dataset. It's a set of hand-written digits that contains 70,000 pictures with their labels. It's divided
in two parts, one training set with 60,000 digits (on which we will train our model) and 10,000 others that form the test. These were drawn by different people from the ones
in the first test, and by evaluating how well on this set, we will see how well it actually generalizes what it learned.&lt;/p&gt;
&lt;p&gt;We'll skip the part as to how to get those sets and how to treat them since it's all shown in the notebook. Let's go to the part where we define our neural net instead. The
pictures we are given have a size of 28 by 28 pixels, each pixel having a value of 0 (white) to 1 (black), so that makes 784 inputs. For this simple model, we choose one
hidden layer of 100 neurons, and then an output size of 10 since we have ten different digits.&lt;/p&gt;
&lt;p&gt;Why 10 and not 1? It's true that in this case we could have asked for just one output going from 0 to 9 (and there are ways to make sure it'd behave like this) but in
image classification problems, we often give as many outputs as they are classes to determine. What if our next problem is to say if the picture if of a dog, a cat, a frog or
a horse? One output won't really represent this, whereas four outputs will certainly help, each of them representing the probability it's in a given class.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="softmax"&gt;
&lt;h2&gt;Softmax&lt;/h2&gt;
&lt;p&gt;When we have a classification problem and a neural network trying to solve it with &lt;span class="math"&gt;\(N\)&lt;/span&gt; outputs (the number of classes), we would like those outputs to represent the probabilities
the input is in each of the classes. To make sure that our final &lt;span class="math"&gt;\(N\)&lt;/span&gt; numbers are all positive and add up to one, we use the softmax activation for the last layer.&lt;/p&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(z_{1},\dots,z_{N}\)&lt;/span&gt; are the last activations given by our final linear layer, instead of pushing them through a ReLU or a sigmoid, we define the outputs
&lt;span class="math"&gt;\(y_{1},\dots,y_{N}\)&lt;/span&gt; by&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y_{i} = \frac{\mathrm{e}^{z_{i}}}{\mathrm{e}^{z_{1}} + \cdots + \mathrm{e}^{z_{N}}} = \frac{\mathrm{e}^{z_{i}}}{\sum_{k=1}^{N} \mathrm{e}^{z_{k}}}.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;As we take the exponentials of the &lt;span class="math"&gt;\(z_{i}\)&lt;/span&gt;, we are sure all of them are positive. Then since we divide by their sum, they must all add up to one, so softmax satisfies
all the prerequisites we wanted for our final output.&lt;/p&gt;
&lt;p&gt;One nice side effect (and which is the reason we chose the exponential) is that if one of the &lt;span class="math"&gt;\(z_{i}\)&lt;/span&gt; is slightly bigger than the other, its exponential will be a lot
bigger. This will have the effect that the corresponding &lt;span class="math"&gt;\(y_{i}\)&lt;/span&gt; will be close to 1, while the other &lt;span class="math"&gt;\(y_{j}\)&lt;/span&gt; are close to zero. Softmax is an activation that really
&lt;em&gt;wants&lt;/em&gt; to pick one class over the other.&lt;/p&gt;
&lt;p&gt;It's not essential, and a neural net could certainly learn with ReLU or sigmoid as its final activation function, but by using softmax we are making it easier for it to have
an output that is close to what we really want, so it will learn faster and generalize better.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="cross-entropy"&gt;
&lt;h2&gt;Cross Entropy&lt;/h2&gt;
&lt;p&gt;To evaluate how badly our model is doing, we had seen the Mean Squared Error loss in the last article. When the output activation function is softmax or a sigmoid, another
function is usually used, called Cross Entropy Loss. If the correct class our model should pick is the &lt;span class="math"&gt;\(i\)&lt;/span&gt;-th, we define the loss as being &lt;span class="math"&gt;\(-\ln(y_{i})\)&lt;/span&gt; when
the output is &lt;span class="math"&gt;\((y_{1},\dots,y_{N})\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since all the &lt;span class="math"&gt;\(y_{i}\)&lt;/span&gt; are between 0 and 1, this loss is a positive number, and it vanishes when &lt;span class="math"&gt;\(y_{i} = 1\)&lt;/span&gt;. If &lt;span class="math"&gt;\(y_{i}\)&lt;/span&gt; is real low though (and we are doing
a mistake in choosing this class) it'll get particularly high.&lt;/p&gt;
&lt;p&gt;If we had multiple correct answers (in a multi-classification problem) we would sum the &lt;span class="math"&gt;\(-\ln(y_{i})\)&lt;/span&gt; over all the correct classes &lt;span class="math"&gt;\(i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note that with the usual formulas, we have&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
ln(y_{i}) = \ln \left ( \frac{\mathrm{e}^{z_{i}}}{\sum_{k=1}^{N} \mathrm{e}^{z_{k}}} \right ) = \ln(\mathrm{e}^{z_{i}}) - \ln \left (  \sum_{k=1}^{N} \mathrm{e}^{z_{k}} \right ) = z_{i} - \ln \left (  \sum_{k=1}^{N} \mathrm{e}^{z_{k}} \right ).
\end{equation*}
&lt;/div&gt;
&lt;p&gt;so the derivative of the loss with respect to &lt;span class="math"&gt;\(z_{i}\)&lt;/span&gt; is&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{\partial \hbox{loss}}{\partial z_{i}} = -1 + \frac{\mathrm{e}^{z_{i}}}{\sum_{k=1}^{N} \mathrm{e}^{z_{k}}} = y_{i} - 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;and the derivative of the loss with respect to &lt;span class="math"&gt;\(z_{j}\)&lt;/span&gt; with &lt;span class="math"&gt;\(j \neq i\)&lt;/span&gt; is&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\frac{\partial \hbox{loss}}{\partial z_{j}} = \frac{\mathrm{e}^{z_{j}}}{\sum_{k=1}^{N} \mathrm{e}^{z_{k}}} = y_{j}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;so it's always &lt;span class="math"&gt;\(y_{j} - \hat{y_{j}}\)&lt;/span&gt;, where &lt;span class="math"&gt;\(\hat{y_{j}}\)&lt;/span&gt; is the output we are supposed to obtain. This simplification makes it easier to compute the gradients, and
it also has the advantage of giving a higher gradient when the error is big, whereas with the MSE loss we'd end up with littler ones, hence learning more slowly.&lt;/p&gt;
&lt;p&gt;In practice, pytorch implemented the computation of log softmax faster than softmax, and since we're using the log of the softmax in our loss function, we'll use
log softmax as the output activation function. The only thing we have to remember is that we'll then receive the logs of the probabilities for our input to be in each class,
which means we'll have to put them through exp if we want to see the actual probabilities.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="writing-our-model"&gt;
&lt;h2&gt;Writing our model&lt;/h2&gt;
&lt;p&gt;In what follows we consider the following imports have been done:&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch.nn&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;nn&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch.nn.functional&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;F&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch.optim&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;optim&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torch.autograd&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Variable&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The first module contains the basic functions of torch, allowing us to build and manipulate tensors, which are the arrays this library handles. The submodule nn contains
all the functions we will need to build a neural net, and its submodule functional has all the functions we will need (like ReLU, softmax...). The aliases are the same as in the
pytorch documentation, and the ones usually used. We'll see what optim and Variable are used for a bit later.&lt;/p&gt;
&lt;p&gt;To write our neural net in pytorch, we create a specific kind of nn.Module, which is the generic pytorch class that handles models. To do so, we only have to create a new
subclass of nn.Module:&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;SimpleNeuralNet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Then in this class, we have to define two functions. The initialization and the forward pass. In the first function, we create the actual layers, with their weights and biases,
and in the second one, we explain how to compute the output from the input.&lt;/p&gt;
&lt;p&gt;In the initialization, we have to remember to initialize the parent class (nn.Module) or we won't be able to use all the properties of those nn.Module, then we just define
our two layers, which can simply be done by using nn.Linear. This is another subclass of nn.Module which represents a classic linear layer. Note that when we have defined
on our custom nn.Module, we can use them inside the definition of another one.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_out&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_in&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_hidden&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;n_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The code is pretty straightforward, our linear layers have been automatically initialized by pytorch, with random weights and biases.
For the forward pass, it's almost as easy, there's just one little problem. Our input is going to be a mini-batch of images. Inside pytorch,
it will be stored as a tensor (think array) of size mb by 1 by 28 by 28, where mb is the number we choose for our mini-batch size (64 in the notebook).&lt;/p&gt;
&lt;p&gt;Why is that? Well it's faster to compute all the outputs of the mini-batch at the same time. If we remember how a linear layer works, we calculate &lt;span class="math"&gt;\(XW + B\)&lt;/span&gt; where
&lt;span class="math"&gt;\(X\)&lt;/span&gt; is the input viewed as a line, &lt;span class="math"&gt;\(W\)&lt;/span&gt; the weight matrix and &lt;span class="math"&gt;\(B\)&lt;/span&gt; the vector of biases. Instead of doing this mb times, we can be more efficient and do all
the operations at once, if we replace &lt;span class="math"&gt;\(X\)&lt;/span&gt; by a matrix, each line being one of the different inputs of the mini-batch: &lt;span class="math"&gt;\(X_{1},\dots,X_{n_{in}}\)&lt;/span&gt;. This way, &lt;span class="math"&gt;\(XW + B'\)&lt;/span&gt;
is going to be a matrix where each line is a vector of outputs, the only trick being to replace &lt;span class="math"&gt;\(B\)&lt;/span&gt; by a matrix with the same number of lines as &lt;span class="math"&gt;\(X\)&lt;/span&gt;, repeating &lt;span class="math"&gt;\(B\)&lt;/span&gt; each time.&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left ( \begin{array}{c} X_{1} \\ X_{2} \\ \vdots \\ X_{n_{in}} \end{array} \right ) \times W + \left ( \begin{array}{c} B \\ B \\ \vdots \\ B \end{array} \right ) = \left ( \begin{array}{c} Y_{1} \\ Y_{2} \\ \vdots \\ Y_{n_{out}} \end{array} \right )
\end{equation*}
&lt;/div&gt;
&lt;p&gt;This process is called vectorization.&lt;/p&gt;
&lt;p&gt;So that explain the first dimension in our tensor. The last two are the actual size of the picture (28 by 28 pixels) and pytorch adds a dimension because he knows our input is
an image, and usually images have three channels (for red, green and blue). We have 1 here because the picture is black and white.&lt;/p&gt;
&lt;p&gt;Following the logic of this vectorization process, the first linear layer is going to expect a tensor of size mb by 784 (which is the result of 28 * 28), so we have to resize
our input (we usually say flatten). To do so, we use the method view:&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;In this line, we tell pytorch to transform x into a two-dimensional array, with a first dimension being the same as the previous value of x, and the second, whatever it needs
to be so that it fits the previous shape of x.&lt;/p&gt;
&lt;p&gt;Once we have this line, the rest of the forward pass is easy: we apply the first linear layer, a ReLU, the second linear layer, and the log softmax. Note that all the functions
we need are in the F (for nn.functional) library.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log_softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Then, we just have to create an instance of our model by calling the class with the arguments it needs (here n_in, n_hidden and n_out).&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;net&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SimpleNeuralNet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;784&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The only parameter we can choose here is the number of neurons in the hidden layer. I've picked 100 but you can try something else.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-training-loop"&gt;
&lt;h2&gt;The training loop&lt;/h2&gt;
&lt;p&gt;Now that we have our model, we must train him to recognize digits. With a random initialization, we can expect it to have a 10%-accuracy at the beginning. But we'll see how
quickly it improves when applying SGD.&lt;/p&gt;
&lt;p&gt;The key thing pytorch provides us with, is automatic differentiation. This means we won't have to compute the gradients ourselves. There is two little things to think of, though.
The first one is that pytorch must remember how an output was created from an input, to be able to roll back from this definition and calculate the gradients. This is done
through the Variable object. Instead of feeding a tensor to our model, we will wrap it in a Variable.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;The new object x still has all the inputs, that we can find in x.data, but this new object has other attributes, one of them being the gradient. If we call the model on x to
get the outputs and feed that in the loss function (with the expected label) we'll be able to get the derivatives of the loss function with respect to x. We told pytorch we would
need them when we typed requires_grad=True.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nll_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Note that we don't use the Cross Entropy loss function since the outputs are already the logarithms of the softmax, and that the labels must also be wrapped inside a Variable.&lt;/p&gt;
&lt;p&gt;Once we have done this, we ask pytorch to compute the gradients of the loss like this:&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;and the derivatives of the loss with respect to x for instance, will be in the Variable x.grad (or x.grad.data if we want the values).&lt;/p&gt;
&lt;p&gt;The second thing we don't want to forget is that pytorch accumulates the gradients. That means he sums there over, each time we call this backward function. This is why we have
to reinitialize them via x.grad.data.zero_ before we want to calculate new derivatives.&lt;/p&gt;
&lt;p&gt;Then, the actual step of the SGD can be done automatically by the use of a pytorch optimizer. We can use the library optim to define one, and will have to pass him the
parameters we want to change at each step (in our case, all the weights and biases in our network) and the learning rate we want to use. Here we define&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;optim&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SGD&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Then we won't need to write the line where we subtract to each parameter the learning rate multiplied by the gradient, this will all be done by calling optimizer.step().
To reinitialize all the gradients of the parameters of our model, we'll just have to type optimizer.zero_grad().&lt;/p&gt;
&lt;p&gt;Once this is all done, we can write our training loop. It consists, for each epoch, in looking through all the data, compute the outputs of each mini-batch of inputs, compare
them with their theoretical labels via the loss function, compute the gradients of the loss functions with respect to all the parameters and adjust them in consequence. We just
had the computation of the accuracy to print how well we are doing at the end of each epoch.&lt;/p&gt;
&lt;pre class="code python literal-block"&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nb_epoch&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nb_epoch&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;running_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.&lt;/span&gt;
        &lt;span class="n"&gt;corrects&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'Epoch {epoch+1}:'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;trn_loader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;#separate the inputs from the labels&lt;/span&gt;
            &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
            &lt;span class="c1"&gt;#wrap those into variables to keep track of how they are created and be able to compute their gradient.&lt;/span&gt;
            &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;#Put the gradients back to zero&lt;/span&gt;
            &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zero_grad&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="c1"&gt;#Compute the outputs given by our model at this stage.&lt;/span&gt;
            &lt;span class="n"&gt;outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;net&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;preds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;#Compute the loss&lt;/span&gt;
            &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;F&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nll_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;running_loss&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;corrects&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;preds&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="c1"&gt;#Backpropagate the computation of the gradients&lt;/span&gt;
            &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;backward&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="c1"&gt;#Do the step of the SGD&lt;/span&gt;
            &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'Loss: {running_loss/len(trn_set)}  Accuracy: {100.*corrects/len(trn_set)}'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;After training our simple neural net for 10 epochs on the train set, we get an accuracy 96.23%. It seems like a great result but we need to see if it generalizes well or
if our model just learned to recognize the particular images of the training set extremely well (we call this overfitting).&lt;/p&gt;
&lt;p&gt;The loop to check how well our model is doing on the test test is very similar to the training loop, minus the gradients, and as shwon on the notebook, we get a 96% accuracy
there. Not bad for such a simple model!&lt;/p&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Neural net"></category><category term="Pytorch"></category></entry><entry><title>What Is Deep Learning?</title><link href="/what-is-deep-learning.html" rel="alternate"></link><published>2018-03-13T17:20:00-04:00</published><updated>2018-03-13T17:20:00-04:00</updated><author><name>Sylvain Gugger</name></author><id>tag:None,2018-03-13:/what-is-deep-learning.html</id><summary type="html">&lt;p class="first last"&gt;What is deep learning? It's a class of algorithms where you train something called a neural net to complete a specific task. Let's begin with a general overview and we will dig into the details in subsequent articles.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;What is deep learning? It's a class of algorithms where you train something called a neural net to complete a specific task. Let's begin with a general overview and we will dig into
the details in subsequent articles.&lt;/p&gt;
&lt;div class="section" id="a-neural-net"&gt;
&lt;h2&gt;A neural net&lt;/h2&gt;
&lt;p&gt;To some extent, a neural net is an attempt by engineers to get a computer to replicate the behavior of our brain. A neuron in our brain gets a .&lt;/p&gt;
&lt;img alt="Neuron model" class="align-center" src="../images/art1_neuron.png" /&gt;
&lt;p&gt;A model of that is to consider a structure getting a certain number of entries, each of them having a weight attributed to them. If this neuron as &lt;span class="math"&gt;\(n\)&lt;/span&gt; entries that are
&lt;span class="math"&gt;\(x_{1},\dots,x_{n}\)&lt;/span&gt;, with the weights &lt;span class="math"&gt;\(w_{1},\dots,w_{n}\)&lt;/span&gt;, we consider the sum of the inputs multiplied by the weight to compute the output:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y = f \left ( w_{1}x_{1} + \cdots + w_{n}x_{n} \right )
\end{equation*}
&lt;/div&gt;
&lt;p&gt;or in a more compact way&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y = f \left ( \sum_{i=1}^{n} w_{i} x_{i} \right ).
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Here &lt;span class="math"&gt;\(y\)&lt;/span&gt; is the output and &lt;span class="math"&gt;\(f\)&lt;/span&gt; a function called the activation function. A few classical activation functions are the rectified linear unit (ReLU), the
sigmoid function or the hyperbolic tangent function:&lt;/p&gt;
&lt;img alt="Graph of the ReLU function" class="align-center" src="../images/art1_relu.png" style="width: 500px;" /&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{ReLU}(x) = \max(0,x)
\end{equation*}
&lt;/div&gt;
&lt;img alt="Graph of the sigmoid function" class="align-center" src="../images/art1_sigmoid.png" style="width: 400px;" /&gt;
&lt;div class="math"&gt;
\begin{equation*}
\sigma(x) = \frac{\mathrm{e}^{x}}{1+\mathrm{e}^{x}}
\end{equation*}
&lt;/div&gt;
&lt;img alt="Graph of the tanh function" class="align-center" src="../images/art1_tanh.png" style="width: 500px;" /&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{tanh}(x) = \frac{\mathrm{e}^{x} - \mathrm{e}^{-x}}{\mathrm{e}^{x} + \mathrm{e}^{-x}}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;The function &lt;span class="math"&gt;\(\hbox{tanh}\)&lt;/span&gt; is actually a sigmoid that we enlarged and translated to go from -1 to 1. To do this, we just have to multiply the sigmoid by 2 (the range between
-1 and 1) then subtract 1:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{tanh}(x) = 2 \sigma(2x) - 1
\end{equation*}
&lt;/div&gt;
&lt;p&gt;These three functions are just the three most popular, but we could take any function, as long as it's non-linear and easy to differentiate (for reasons we will see later).&lt;/p&gt;
&lt;p&gt;One last parameter we usually consider in our neuron is something called a bias, that is added to the weighted sum of the inputs before going into the activation function.&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y = f \left ( \sum_{i=1}^{n} w_{i} x_{i} + b \right ).
\end{equation*}
&lt;/div&gt;
&lt;p&gt;If we consider the case of a ReLU activation function (which basically replaces the negative by zero), the opposite of this bias is then the minimum value to reach to get an
output that isn't nil.&lt;/p&gt;
&lt;p&gt;So that's one neuron. In a neural net, we have quite a few of them, regrouped in what we call layers. An example of neural net with a single layer would look like this:&lt;/p&gt;
&lt;img alt="Neural net with one layer" class="align-center" src="../images/art1_simplennet.jpg" /&gt;
&lt;p&gt;So let's say we want to build a neural net with an input size &lt;span class="math"&gt;\(n_{in}\)&lt;/span&gt; and an output size &lt;span class="math"&gt;\(n_{out}\)&lt;/span&gt;. We then must have &lt;span class="math"&gt;\(n_{out}\)&lt;/span&gt; neurons.
Each one of our neurons then has &lt;span class="math"&gt;\(n_{in}\)&lt;/span&gt; inputs, so it must have as many weights. If we consider the neuron number &lt;span class="math"&gt;\(i\)&lt;/span&gt; we can call this weights
&lt;span class="math"&gt;\(w_{1,i},\dots,w_{n_{in},i}\)&lt;/span&gt; and the bias of the neuron &lt;span class="math"&gt;\(b_{i}\)&lt;/span&gt; then the output number &lt;span class="math"&gt;\(i\)&lt;/span&gt; is&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
y_{i} = f \left ( \sum_{k=1}^{n_{in}} x_{k} w_{k,i} + b_{i} \right )
\end{equation*}
&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(x_{1},\dots,x_{n_{in}}\)&lt;/span&gt; are the coordinates of the input. There is a more compact way to write this, with a little bit of linear algebra. The big sum inside the
parenthesis is just the i-th coordinate of the matrix product &lt;span class="math"&gt;\(XW\)&lt;/span&gt; if we define the matrix &lt;span class="math"&gt;\(W\)&lt;/span&gt; as the array of weights &lt;span class="math"&gt;\((w_{i,k})\)&lt;/span&gt; (with &lt;span class="math"&gt;\(n_{in}\)&lt;/span&gt; rows and
&lt;span class="math"&gt;\(n_{out}\)&lt;/span&gt; columns) and &lt;span class="math"&gt;\(X\)&lt;/span&gt; is a vector containing the inputs (viewed as a single row). If we then note &lt;span class="math"&gt;\(Y\)&lt;/span&gt; the vector containing the outputs and &lt;span class="math"&gt;\(B\)&lt;/span&gt; the
vector containing the biases (both have &lt;span class="math"&gt;\(n_{out}\)&lt;/span&gt; coordinates), we can simply write&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
Y = f(XW + B)
\end{equation*}
&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(f\)&lt;/span&gt; is applied to each one of the coordinates of the vector &lt;span class="math"&gt;\(XW + B\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;This is the only thing a neural net does, apply a linear operation then an activation function. Except it does that many times: instead of having just one layer of neurons, we
have multiple ones, each one feeding the next.&lt;/p&gt;
&lt;img alt="Neural net with three layers" class="align-center" src="../images/art1_complexnnet.png" /&gt;
&lt;p&gt;Here we have three layers, each one having its own set of weights &lt;span class="math"&gt;\(W_{l}\)&lt;/span&gt;, its vector of biases &lt;span class="math"&gt;\(B_{l}\)&lt;/span&gt; and its activation function &lt;span class="math"&gt;\(f_{l}\)&lt;/span&gt;. The only constraint
is that each vector of bias as the same number of coordinates as the number of columns of the weigh matrix, which must also be the number of rows of the next weight matrix.&lt;/p&gt;
&lt;p&gt;If we have an input &lt;span class="math"&gt;\(X\)&lt;/span&gt;, we compute the output by going through each layer, one after the other:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\left \{ \begin{array}{l} X_{0} = X \\ X_{1} = f_{0}(X_{0}W_{1} + B_{1}) \\ X_{2} = f_{1}(X_{1}W_{2} + B_{2}) \\ \vdots \\ X_{L} = f_{L}(X_{L-1}W_{L} + B_{L}) \end{array} \right .
\end{equation*}
&lt;/div&gt;
&lt;p&gt;where &lt;span class="math"&gt;\(L\)&lt;/span&gt; is the number of layers. This is when we see why each activation function must be non-linear. If one (say &lt;span class="math"&gt;\(f_{0}\)&lt;/span&gt;) was linear, the operations
going from &lt;span class="math"&gt;\(X_{0}\)&lt;/span&gt; to &lt;span class="math"&gt;\(X_{1}W_{2} + B_{2}\)&lt;/span&gt; would all be linear, so they could be summarized in to&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
X_{1}W_{2} + B_{2} = X_{0}W'_{1} + B'_{1}
\end{equation*}
&lt;/div&gt;
&lt;p&gt;and there wouldn't be any need to have that initial first layer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="training"&gt;
&lt;h2&gt;Training&lt;/h2&gt;
&lt;p&gt;Now that we know what a neural net is, we can study how we can teach him to solve a particular problem. All the weights and the biases of the neural net we saw before (that are
called the parameters of our model) are initialized at random, so initially, the output the neural net will compute has nothing to do with what we would expect. It's through
a process called training that we will make our model better.&lt;/p&gt;
&lt;p&gt;To do this, we need a set of labeled data, which is a collection of inputs where we know the desired output, for instance, in an image classification problem, pictures that have
been classified for us. We can then evaluate how badly our model is doing by computing all the outputs and comparing them to the theoretical ones. To give a value to this, we
use an error function.&lt;/p&gt;
&lt;p&gt;An error function that is often used is called MSE for Mean Squared Errors. If &lt;span class="math"&gt;\(Y\)&lt;/span&gt; is the output we computed and &lt;span class="math"&gt;\(Z\)&lt;/span&gt; the one we should have found, one way to see
how far away &lt;span class="math"&gt;\(Y\)&lt;/span&gt; is from &lt;span class="math"&gt;\(Z\)&lt;/span&gt; is to take the mean of the errors between each coordinate &lt;span class="math"&gt;\(y_{i}\)&lt;/span&gt; and &lt;span class="math"&gt;\(z_{i}\)&lt;/span&gt;. This error can be represented by
&lt;span class="math"&gt;\((z_{i}-y_{i})^{2}\)&lt;/span&gt;. The square is to get rid of the negatives (an error of -4 is as bas as an error of 4). If &lt;span class="math"&gt;\(Y\)&lt;/span&gt; and &lt;span class="math"&gt;\(Z\)&lt;/span&gt; are of size &lt;span class="math"&gt;\(n_{out}\)&lt;/span&gt;, this
can be written&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{MSE}(Y,Z) = \frac{1}{n_{out}} \sum_{i=1}^{n_{out}} (z_{i}-y_{i})^{2}.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;And then we can define the total loss by taking the mean of the loss on all our data. If we have &lt;span class="math"&gt;\(N\)&lt;/span&gt; inputs &lt;span class="math"&gt;\(X_{1},\dots,X_{N}\)&lt;/span&gt; that are labeled
&lt;span class="math"&gt;\(Z_{1},\dots,Z_{N}\)&lt;/span&gt; (the theoretical outputs we are supposed to get), by computing what the network returns when you feed it the &lt;span class="math"&gt;\(X_{i}\)&lt;/span&gt; and naming this as
&lt;span class="math"&gt;\(Y_{i}\)&lt;/span&gt; we then have&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{loss} = \frac{1}{N} \sum_{k=1}^{N} \hbox{MSE}(Y_{k},Z_{k})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;Any kind of function could be used for the loss, as long as it's always positive (you don't want to subtract things from previous losses), that it only vanishes at zero, and
that it's easy to differentiate. The total loss is always taken by averaging the loss on all the samples of the dataset.&lt;/p&gt;
&lt;p&gt;Since the network's parameters are initialized at random, this loss will be pretty bad at the beginning. Training is a process during which the computer will compute this loss,
analyze why it's so bad, and try to do a little bit better the next time. More specifically, we will try to determine a new set of parameters (all the weights and the biases)
that will give us a slightly better loss. Then by repeating this over and over again, we should find the set of parameters that minimize this loss.&lt;/p&gt;
&lt;p&gt;The exciting thing with neural networks, is that even if they learn on a specific dataset, they tend to generalize pretty well (and there's a bunch of techniques we can use to
make sure the model doesn't overfit to the training data). In image recognition for instance, those kinds of models can have better accuracy than humans do.&lt;/p&gt;
&lt;p&gt;To minimize this loss, we use an algorithm called SGD for Stochastic Gradient Descent. The idea is fairly simple: if you're in the mountains and looking for the point that is
at the lowest altitude, you just take a step down, and a step down, and so forth until you reach that particular spot. This is going to be exactly the same for our neural
net and its loss. To minimize that function, we will take a little step down.&lt;/p&gt;
&lt;p&gt;This function loss depends of a certain amount of parameters &lt;span class="math"&gt;\(p_{1},\dots,p_{t}\)&lt;/span&gt; (all the weights and all the biases). Now, with just a little bit of math, we know that
the way down for a function of &lt;span class="math"&gt;\(t\)&lt;/span&gt; variables (which is the direction where it's steeper) is given by the opposite of the gradient. This is the vector&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\overrightarrow{\hbox{grad}}(\hbox{loss}) = \left ( \frac{\partial \hbox{loss}}{\partial p_{1}}, \dots, \frac{\partial \hbox{loss}}{\partial p_{t}} \right )
\end{equation*}
&lt;/div&gt;
&lt;p&gt;To update our parameters, which just have to take a step along the opposite of the gradients, which means subtract to the vector &lt;span class="math"&gt;\((p_{1},\dots,p_{t})\)&lt;/span&gt; a little bit
multiplied by this gradient vector. How much? That's the question that has been driving crazy a lot of data scientists, and we will give an answer in another article.
This little bit is called the learning rate, and if we note it &lt;span class="math"&gt;\(\hbox{lr}\)&lt;/span&gt; we can update our parameters with the formulas:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{new } p_{i} = \hbox{old } p_{i} - \hbox{lr} \times \frac{\partial \hbox{loss}}{\partial p_{i}}.
\end{equation*}
&lt;/div&gt;
&lt;p&gt;By doing this, we know that the loss, the next time we compute all the outputs of all our data, is going to be better (the only exception would be if we chose a too high learning
rate, which would make us miss the spot where our function was lowest, but we'll get back to this later). So by repeating this step over and over again, we will eventually get
to a minimum of our loss function, and a very good model.&lt;/p&gt;
&lt;p&gt;This explains the Gradient Descent in SGD but not the Stochastic part. The random part appears by necessity: very often our training dataset has a lot of labeled inputs. It can
be as big as a million images. That's why, for a step of gradient descent, we don't compute the total loss, but rather the loss on a smaller sample called a mini-batch. If we
choose to take the sample &lt;span class="math"&gt;\((X_{k_{1}},Z_{k_{1}}),\dots,(X_{k_{mb}},Z_{k_{mb}})\)&lt;/span&gt; the loss on this mini-batch will just be:&lt;/p&gt;
&lt;div class="math"&gt;
\begin{equation*}
\hbox{loss}' = \frac{1}{mb} \sum_{q=1}^{mb} \hbox{MSE}(Y_{k_{q}},Z_{k_{q}})
\end{equation*}
&lt;/div&gt;
&lt;p&gt;The idea is that this new loss will have a gradient that is close to the gradient of the real loss (since we're averaging on a mini-batch and not just taking one sample) but with
fewer computation time. In practice, to make sure we still see all of the data, we don't overlap the mini-batches, taking different parts of our training set each time we randomly
pick a mini-batch, and updating all the parameters of our network each time, up until we have seen all the inputs once. This whole process is called an epoch.&lt;/p&gt;
&lt;p&gt;We can then run as many epochs as we want (or as we have time to), as long as the learning rate is low enough, the neural network should progress and become better each time.
The gradient may seem a bit complicated to evaluate, but it can be computed exactly by using the chain rule, going backward from the end (compute the derivatives of the loss
function with respects to the obtained outputs), through each layer, up until the beginning.&lt;/p&gt;
&lt;p&gt;That is all the general theory behind a neural network. I will dig more into the details in further articles to explain the different layers we can find, the little tweaks we can
add to SGD to make it train faster, how to set the learning rate and how to compute those gradients. We'll see how to code simple and more complex examples of neural networks
in pytorch, but you can already jump a bit ahead and look at the &lt;a class="reference external" href="http://course.fast.ai/lessons/lesson1.html"&gt;first video&lt;/a&gt; of the deep-learning course of fast.ai, and train in a few minutes a neural net recognizing cats from
dogs with 99% accuracy.&lt;/p&gt;
&lt;/div&gt;
&lt;script type='text/javascript'&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Neural Net"></category><category term="SGD"></category></entry><entry><title>Why Write A Blog?</title><link href="/why-write-a-blog.html" rel="alternate"></link><published>2018-03-12T16:57:00-04:00</published><updated>2018-03-12T16:57:00-04:00</updated><author><name>Sylvain Gugger</name></author><id>tag:None,2018-03-12:/why-write-a-blog.html</id><summary type="html">&lt;p&gt;I've just been accepted to follow the 2018 version of Deep learning - part 2 on &lt;a class="reference external" href="http://fast.ai/"&gt;fast.ai&lt;/a&gt;, and I'm pretty excited about it. As I'm reaching the stage at which this is becoming more
than a hobby and the plan is to switch careers to Data Science, I've taken the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've just been accepted to follow the 2018 version of Deep learning - part 2 on &lt;a class="reference external" href="http://fast.ai/"&gt;fast.ai&lt;/a&gt;, and I'm pretty excited about it. As I'm reaching the stage at which this is becoming more
than a hobby and the plan is to switch careers to Data Science, I've taken the time to ponder all the alternatives and I've settled on self-studying.&lt;/p&gt;
&lt;p&gt;Which brings me to this blog. How do you measure your progress when there's no one to grade your work? One solution I've found is to write about what I learn. Nothing here is going
to be new, I simply intend to explain in my own words concepts that have been detailed elsewhere (probably with fewer grammatical mistakes!). I could say that
my only reader is going to be my mom, but she doesn't read English, so that won't even be the case. As an ex-teacher, I simply believe you've
never completely mastered something until you've taught it to someone else.&lt;/p&gt;
&lt;p&gt;For now the curriculum I have settled on is:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;the deep learning course of &lt;a class="reference external" href="http://fast.ai/"&gt;fast.ai&lt;/a&gt; (part 1 and 2);&lt;/li&gt;
&lt;li&gt;the machine learning course of &lt;a class="reference external" href="http://fast.ai/"&gt;fast.ai&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;the online book of &lt;a class="reference external" href="http://neuralnetworksanddeeplearning.com/"&gt;Michael Nielsen&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Python for data analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will update this list as it grows. I will try to get to the bottom of all the concepts I learn, and I intend to code everything from scratch. Since the
fast.ai library is wrapped on top of pytorch, this is the library I will mostly use, along with numpy and pandas. All these articles will be in the Deep learning category.&lt;/p&gt;
&lt;p&gt;I also plan to play along with different approaches and parameters, to highlight the importance of each decision we make when building a model. To that end, I'll design and
implement as many experiments as I can and put the results in the Experiments category.&lt;/p&gt;
&lt;p&gt;Explaining things is all very good, but it's even better to show what you can actually do. I plan to enter a few &lt;a class="reference external" href="http://kaggle.com/"&gt;Kaggle&lt;/a&gt; competitions, hopefully achieve a good ranking,
and I will also use some of the articles of this blog as a portfolio to demonstrate my skills. Those articles will be in the Portfolio category.&lt;/p&gt;
</content></entry></feed>